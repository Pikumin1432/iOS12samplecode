{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, AveragePooling2D, Conv2D, Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K # tensorflow\n",
    "\n",
    "import coremltools\n",
    "from coremltools.proto import NeuralNetwork_pb2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kears_file = \"./KerasMNIST_customlayer.h5\"\n",
    "coreml_file = './KerasMNIST_customlayer.mlmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_learn_keras_model():\n",
    "\n",
    "    # Just sigmoid\n",
    "    def custom_sigmoid_activation(x):\n",
    "        return K.sigmoid(x)\n",
    "\n",
    "    # Just relu\n",
    "    def custom_relu_activation(x):\n",
    "        return K.relu(x)\n",
    "\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 10\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_train.shape[1:])\n",
    "\n",
    "    img_rows = 28\n",
    "    img_cols = 28\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    # 入力値の正規化\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # 教師データをクラス分類のデータに変換\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # ネットワーク設計\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=[3, 3], padding='same', input_shape=input_shape))\n",
    "\n",
    "    # custom layer\n",
    "    model.add(Lambda(custom_sigmoid_activation))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=[3, 3], padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, kernel_size=[3, 3], padding='same', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "\n",
    "    # custom layer\n",
    "    model.add(Lambda(custom_relu_activation))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # ネットワークの構成を出力する\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 16)        4624      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "lambda_8 (Lambda)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 417,018\n",
      "Trainable params: 417,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.5317 - acc: 0.8236 - val_loss: 0.0931 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0885 - acc: 0.9727 - val_loss: 0.0714 - val_acc: 0.9759\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0574 - acc: 0.9824 - val_loss: 0.0484 - val_acc: 0.9832\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0413 - acc: 0.9870 - val_loss: 0.0462 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0325 - acc: 0.9900 - val_loss: 0.0472 - val_acc: 0.9844\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0254 - acc: 0.9922 - val_loss: 0.0446 - val_acc: 0.9865\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0422 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.0461 - val_acc: 0.9877\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0527 - val_acc: 0.9873\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0484 - val_acc: 0.9883\n",
      "('Test loss:', 0.048389283512356725)\n",
      "('Test accuracy:', 0.9883)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(kears_file):\n",
    "    keras_model = build_and_learn_keras_model()\n",
    "    keras_model.save(kears_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_10_input, <keras.engine.topology.InputLayer object at 0x17b027950>\n",
      "1 : conv2d_10, <keras.layers.convolutional.Conv2D object at 0x17b027990>\n",
      "2 : lambda_7, <keras.layers.core.Lambda object at 0x17b027b50>\n",
      "3 : conv2d_11, <keras.layers.convolutional.Conv2D object at 0x17b022c10>\n",
      "4 : conv2d_11__activation__, <keras.layers.core.Activation object at 0x16cf9f610>\n",
      "5 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x16ce9b510>\n",
      "6 : conv2d_12, <keras.layers.convolutional.Conv2D object at 0x16ceb03d0>\n",
      "7 : conv2d_12__activation__, <keras.layers.core.Activation object at 0x16cf9f0d0>\n",
      "8 : flatten_4, <keras.layers.core.Flatten object at 0x16cec4dd0>\n",
      "9 : dense_7, <keras.layers.core.Dense object at 0x16ceda3d0>\n",
      "10 : lambda_8, <keras.layers.core.Lambda object at 0x17b027b90>\n",
      "11 : dense_8, <keras.layers.core.Dense object at 0x16cf0ab90>\n",
      "12 : dense_8__activation__, <keras.layers.core.Activation object at 0x16e2db710>\n"
     ]
    }
   ],
   "source": [
    "def convert_custom_lambda_layer(layer):\n",
    "    \n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "    \n",
    "    if layer.function.__name__ == custom_relu_activation.__name__:\n",
    "        params.className = \"custom_relu_activation\"\n",
    "        params.description = \"RELU\"\n",
    "        return params\n",
    "    elif layer.function.__name__ == custom_sigmoid_activation.__name__:\n",
    "        params.className = \"custom_sigmoid_activation\"\n",
    "        params.description = \"sigmoid\"\n",
    "        return params\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert(\n",
    "    kears_file,\n",
    "    input_names='image',\n",
    "    output_names='digit',\n",
    "    add_custom_layers=True,\n",
    "    custom_conversion_functions={ \"Lambda\": convert_custom_lambda_layer }\n",
    ")\n",
    "\n",
    "coreml_model.author = u'Yuichi Yoshida'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = u'Custom layerのサンプル'\n",
    "\n",
    "coreml_model.input_description['image'] = u'入力画像'\n",
    "coreml_model.output_description['digit'] = u'推定した数字の確率'\n",
    "\n",
    "coreml_model.save(coreml_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
